# INT8 GEMM

W8A16 (INT8 weights, FP16 activations) matrix multiplication kernels for efficient inference.

## Functions

::: rotalabs_accel.kernels.gemm.int8_gemm

::: rotalabs_accel.kernels.gemm.int8_gemm_torch

## Classes

::: rotalabs_accel.kernels.gemm.Int8Linear
